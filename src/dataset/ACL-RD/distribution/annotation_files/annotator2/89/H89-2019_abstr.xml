<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="H89-2019">  <Title>A PROPOSAL FOR SLS EVALUATION</Title>  <Section>    <SectionTitle>ABSTRACT</SectionTitle>    <S>This paper proposes an automatic, essentially domain-independent means of evaluating <term class="tech">Spoken Language Systems (SLS)</term> which combines software we have developed for that purpose (the <term class="tool">Comparator</term>) and a set of <term class="model">specifications</term> for <term class="other">answer expressions</term> (the <term class="tool">Common Answer Specification</term>, or <term class="tool">CAS</term>).</S>    <S>The <term class="tool">Comparator</term> checks whether the answer provided by a <term class="tech">SLS</term> accords with a <term class="other">canonical answer</term>, returning either true or false.</S>    <S>The <term class="tool">Common Answer Specification</term> determines the <term class="other">syntax</term> of <term class="other">answer expressions</term>, the minimal content that must be included in them, the data to be included in and excluded from <term class="lr">test corpora</term>, and the procedures used by the <term class="tool">Comparator</term>.</S>    <S>Though some details of the <term class="tool">CAS</term> are particular to individual <term class="other">domains</term>, the <term class="tool">Comparator software</term> is domain-independent, as is the <term class="tool">CAS approach</term>.</S>  </Section></Paper>