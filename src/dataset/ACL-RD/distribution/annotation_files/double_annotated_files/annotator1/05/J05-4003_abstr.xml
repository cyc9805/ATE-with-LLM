<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="J05-4003">  <Title>Improving Machine Translation Performance by Exploiting Non-Parallel Corpora</Title>  <Section>    <SectionTitle/>    <S>We present a novel method for <term class="tech">discovering parallel sentences</term> in <term class="lr">comparable, non-parallel corpora</term>.</S>    <S>We train a <term class="tech">maximum entropy classifier</term> that, given a pair of <term class="other">sentences</term>, can reliably determine whether or not they are <term class="other">translations</term> of each other.</S>    <S>Using this approach, we extract <term class="lr">parallel data</term> from large <term class="lr">Chinese, Arabic, and English non-parallel newspaper corpora</term>.</S>    <S>We evaluate the <term class="measure(ment)">quality of the extracted data</term> by showing that it improves the performance of a state-of-the-art <term class="tech">statistical machine translation system</term>.</S>    <S>We also show that a good-quality <term class="tech">MT system</term> can be built from scratch by starting with a very small <term class="lr">parallel corpus</term> (100,000 <term class="other">words</term>) and exploiting a large <term class="lr">non-parallel corpus</term>.</S>    <S>Thus, our method can be applied with great benefit to <term class="other">language pairs</term> for which only scarce <term class="lr">resources</term> are available.</S>  </Section></Paper>