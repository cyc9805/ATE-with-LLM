<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="N03-1017">	<Title>Statistical Phrase-Based Translation</Title>		<Section>			<SectionTitle>Abstract</SectionTitle>			<S>We propose a new <term class="model">phrase-based translation model</term> and <term class="tech">decoding algorithm</term> that enables us to evaluate and compare several, previously proposed <term class="model">phrase-based translation models</term>.</S>			<S>Within our framework, we carry out a large number of experiments to understand better and explain why <term class="model">phrase-based models</term> outperform <term class="model">word-based models</term>.</S>			<S>Our empirical results, which hold for all examined <term class="other">language pairs</term>, suggest that the highest levels of performance can be obtained through relatively simple means: <term class="tech">heuristic learning</term> of <term class="other">phrase translations</term> from <term class="lr">word-based alignments</term> and <term class="tech">lexical weighting</term> of <term class="other">phrase translations</term>.</S>			<S>Surprisingly, learning <term class="other">phrases</term> longer than three <term class="other">words</term> and learning <term class="other">phrases</term> from <term class="model">high-accuracy word-level alignment models</term> does not have a strong impact on performance.</S>			<S>Learning only <term class="other">syntactically motivated phrases</term> degrades the performance of our systems.</S>		</Section></Paper>