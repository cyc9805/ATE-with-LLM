<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="P03-1051">
<Title>Language Model Based Arabic Word Segmentation</Title>
<Section>
<SectionTitle>Abstract</SectionTitle>
<S id="1"><token id="1">We</token><token id="2">approximate</token><term class.1="other"><token id="3">Arabic's</token><token id="4">rich</token><token id="5">morphology</token></term><token id="6">by</token><token id="7">a</token><term class.1="model"><token id="8">model</token></term><token id="9">that</token><token id="10">a</token><term class.1="other"><token id="11">word</token></term><token id="12">consists</token><token id="13">of</token><token id="14">a</token><token id="15">sequence</token><token id="16">of</token><term class.1="other"><token id="17">morphemes</token></term><token id="18">in</token><token id="19">the</token><term class.1="other"><token id="20">pattern</token></term><term class.1="other"><token id="21">prefix*-stem-suffix*</token></term><token id="22">(</token><token id="23">*</token><token id="24">denotes</token><token id="25">zero</token><token id="26">or</token><token id="27">more</token><token id="28">occurrences</token><token id="29">of</token><token id="30">a</token><term class.1="other"><token id="31">morpheme</token></term><token id="32">)</token><token id="33">.</token></S><S id="2"><token id="1">Our</token><token id="2">method</token><token id="3">is</token><token id="4">seeded</token><token id="5">by</token><token id="6">a</token><token id="7">small</token><term class.1="lr"><token id="8">manually</token><token id="9">segmented</token><token id="10">Arabic</token><token id="11">corpus</token></term><token id="12">and</token><token id="13">uses</token><token id="14">it</token><token id="15">to</token><token id="16">bootstrap</token><token id="17">an</token><term class.1="tech"><token id="18">unsupervised</token><token id="19">algorithm</token></term><token id="20">to</token><token id="21">build</token><token id="22">the</token><term class.1="tech"><token id="23">Arabic</token><token id="24">word</token><token id="25">segmenter</token></term><token id="26">from</token><token id="27">a</token><token id="28">large</token><term class.1="lr"><token id="29">unsegmented</token><token id="30">Arabic</token><token id="31">corpus</token></term><token id="32">.</token></S><S id="3"><token id="1">The</token><token id="2">algorithm</token><token id="3">uses</token><token id="4">a</token><term class.1="model"><token id="5">trigram</token><token id="6">language</token><token id="7">model</token></term><token id="8">to</token><token id="9">determine</token><token id="10">the</token><token id="11">most</token><token id="12">probable</token><term class.1="other"><token id="13">morpheme</token><token id="14">sequence</token></term><token id="15">for</token><token id="16">a</token><token id="17">given</token><term class.1="other"><token id="18">input</token></term><token id="19">.</token></S><S id="4"><token id="1">The</token><term class.1="model"><token id="2">language</token><token id="3">model</token></term><token id="4">is</token><token id="5">initially</token><token id="6">estimated</token><token id="7">from</token><token id="8">a</token><token id="9">small</token><term class.1="lr"><token id="10">manually</token><token id="11">segmented</token><token id="12">corpus</token></term><token id="13">of</token><token id="14">about</token><token id="15">110</token><token id="16">,000</token><term class.1="other"><token id="17">words</token></term><token id="18">.</token></S><S id="5"><token id="1">To</token><token id="2">improve</token><token id="3">the</token><term class.1="tech"><token id="4">segmentation</token></term><term class.1="measure(ment)"><token id="5">accuracy</token></term><token id="6">,</token><token id="7">we</token><token id="8">use</token><token id="9">an</token><term class.1="tech"><token id="10">unsupervised</token><token id="11">algorithm</token></term><token id="12">for</token><token id="13">automatically</token><token id="14">acquiring</token><token id="15">new</token><term class.1="other"><token id="16">stems</token></term><token id="17">from</token><token id="18">a</token><token id="19">155</token><token id="20">million</token><term class.1="other"><token id="21">word</token></term><term class.1="lr"><token id="22">unsegmented</token><token id="23">corpus</token></term><token id="24">,</token><token id="25">and</token><token id="26">re-estimate</token><token id="27">the</token><term class.1="other"><token id="28">model</token><token id="29">parameters</token></term><token id="30">with</token><token id="31">the</token><token id="32">expanded</token><term class.1="other"><token id="33">vocabulary</token></term><token id="34">and</token><term class.1="lr"><token id="35">training</token><token id="36">corpus</token></term><token id="37">.</token></S><S id="6"><token id="1">The</token><token id="2">resulting</token><term class.1="tech"><token id="3">Arabic</token><token id="4">word</token><token id="5">segmentation</token><token id="6">system</token></term><token id="7">achieves</token><token id="8">around</token><token id="9">97%</token><term class.1="measure(ment)"><token id="10">exact</token><token id="11">match</token><token id="12">accuracy</token></term><token id="13">on</token><token id="14">a</token><term class.1="lr"><token id="15">test</token><token id="16">corpus</token></term><token id="17">containing</token><token id="18">28</token><token id="19">,449</token><term class.1="other"><token id="20">word</token><token id="21">tokens</token></term><token id="22">.</token></S><S id="7"><token id="1">We</token><token id="2">believe</token><token id="3">this</token><token id="4">is</token><token id="5">a</token><token id="6">state-of-the-art</token><token id="7">performance</token><token id="8">and</token><token id="9">the</token><token id="10">algorithm</token><token id="11">can</token><token id="12">be</token><token id="13">used</token><token id="14">for</token><token id="15">many</token><term class.1="other"><token id="16">highly</token><token id="17">inflected</token><token id="18">languages</token></term><token id="19">provided</token><token id="20">that</token><token id="21">one</token><token id="22">can</token><token id="23">create</token><token id="24">a</token><token id="25">small</token><term class.1="lr"><token id="26">manually</token><token id="27">segmented</token><token id="28">corpus</token></term><token id="29">of</token><token id="30">the</token><term class.1="other"><token id="31">language</token></term><token id="32">of</token><token id="33">interest</token><token id="34">.</token></S></Section></Paper>