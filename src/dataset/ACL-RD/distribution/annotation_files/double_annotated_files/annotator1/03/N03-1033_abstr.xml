<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="N03-1033">	<Title>Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network</Title>		<Section>			<SectionTitle>Abstract</SectionTitle>			<S>We present a new <term class="tech">part-of-speech tagger</term> that demonstrates the following ideas: (i) explicit use of both preceding and following <term class="other">tag contexts</term> via a <term class="other">dependency network representation</term>, (ii) broad use of <term class="other">lexical features</term>, including <term class="tech">jointly conditioning on multiple consecutive words</term>, (iii) effective use of <term class="other">priors</term> in <term class="model">conditional loglinear models</term>, and (iv) fine-grained modeling of <term class="other">unknown word features</term>.</S>			<S>Using these ideas together, the resulting <term class="tech">tagger</term> gives a 97.24% <term class="measure(ment)">accuracy</term> on the <term class="lr-prod">Penn Treebank WSJ</term>, an <term class="measure(ment)">error reduction</term> of 4.4% on the best previous single automatically learned <term class="tech">tagging</term> result.</S>		</Section></Paper>