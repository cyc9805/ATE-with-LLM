<?xml version="1.0" ?>
<Paper acl-id="E06-1035">
  <Title>Automatic Segmentation of Multiparty Dialogue</Title>
  <Section>
    <SectionTitle>Abstract</SectionTitle>
    <S>In this paper, we investigate the problem of automatically predicting segment boundaries in spoken multiparty dialogue.</S>
    <S>We extend prior work in two ways.</S>
    <S>We first apply approaches that have been proposed for predicting top-level topic shifts to the problem of identifying subtopic boundaries.</S>
    <S>We then explore the impact on performance of using ASR output as opposed to human transcription.</S>
    <S>Examination of the effect of features shows that predicting top-level and predicting subtopic boundaries are two distinct tasks: (1) for predicting subtopic boundaries, the lexical cohesion-based approach alone can achieve competitive results, (2) for predicting top-level boundaries, the machine learning approach that combines lexical-cohesion and conversational features performs best, and (3) conversational cues, such as cue phrases and overlapping speech, are better indicators for the top-level prediction task.</S>
    <S>We also find that the transcription errors inevitable in ASR output have a negative impact on models that combine lexical-cohesion and conversational features, but do not change the general preference of approach for the two tasks.</S>
  </Section></Paper>