<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="N03-1001">	<Title>Effective Utterance Classification with Unsupervised Phonotactic Models</Title>		<Section>			<SectionTitle>Abstract</SectionTitle>			<S>This paper describes a method for <term class="tech">utterance classification</term> that does not require <term class="other">manual transcription</term> of <term class="lr">training data</term>.</S>			<S>The method combines <term class="model">domain independent acoustic models</term> with off-the-shelf <term class="tech">classifiers</term> to give <term class="measure(ment)">utterance classification performance</term> that is surprisingly close to what can be achieved using conventional <term class="tech">word-trigram recognition</term> requiring <term class="other">manual transcription</term>.</S>			<S>In our method, <term class="tech">unsupervised training</term> is first used to train a <term class="model">phone n-gram model</term> for a particular <term class="other">domain</term>; the <term class="other">output</term> of <term class="tech">recognition</term> with this <term class="model">model</term> is then passed to a <term class="tech">phone-string classifier</term>.</S>			<S>The <term class="measure(ment)">classification accuracy</term> of the method is evaluated on three different <term class="other">spoken language system domains</term>.</S>		</Section></Paper>