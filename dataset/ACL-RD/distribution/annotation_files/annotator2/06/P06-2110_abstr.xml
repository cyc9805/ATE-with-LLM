<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="P06-2110">  <Title>Word Vectors and Two Kinds of Similarity</Title>  <Section>    <SectionTitle>Abstract</SectionTitle>    <S>This paper examines what kind of <term class="other">similarity</term> between <term class="other">words</term> can be represented by what kind of <term class="model">word vectors</term> in the <term class="tech">vector space model</term>.</S>    <S>Through two experiments, three methods for constructing <term class="model">word vectors</term>, i.e., <term class="tech">LSA-based, cooccurrence-based and dictionary-based methods</term>, were compared in terms of the ability to represent two kinds of <term class="other">similarity</term>, i.e., <term class="other">taxonomic similarity</term> and <term class="other">associative similarity</term>.</S>    <S>The result of the comparison was that the <term class="model">dictionary-based word vectors</term> better reflect <term class="other">taxonomic similarity</term>, while the <term class="model">LSA-based and the cooccurrence-based word vectors</term> better reflect <term class="other">associative similarity</term>.</S>  </Section></Paper>