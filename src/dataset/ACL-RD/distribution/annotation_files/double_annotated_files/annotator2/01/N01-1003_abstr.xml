<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="N01-1003">  <Title>SPoT: A Trainable Sentence Planner</Title>  <Section>    <SectionTitle>Abstract</SectionTitle>    <S>         <term class="tech">Sentence planning</term> is a set of inter-related but distinct tasks, one of which is <term class="tech">sentence scoping</term>, i.e. the choice of <term class="other">syntactic structure</term> for <term class="other">elementary speech acts</term> and the decision of how to combine them into one or more <term class="other">sentences</term>.</S>    <S>In this paper, we present <term class="tool">SPoT</term>, a <term class="tech">sentence planner</term>, and a new methodology for automatically training <term class="tool">SPoT</term> on the basis of <term class="model">feedback</term> provided by <term class="other">human judges</term>.</S>    <S>We reconceptualize the task into two distinct phases.</S>    <S>First, a very simple, <term class="tech">randomized sentence-plan-generator (SPG)</term> generates a potentially large list of possible <term class="other">sentence plans</term> for a given <term class="other">text-plan input</term>.</S>    <S>Second, the <term class="tech">sentence-plan-ranker (SPR)</term> ranks the list of <term class="other">output sentence plans</term>, and then selects the <term class="other">top-ranked plan</term>.</S>    <S>The <term class="tech">SPR</term> uses <term class="model">ranking rules</term> automatically learned from <term class="lr">training data</term>.</S>    <S>We show that the trained <term class="tech">SPR</term> learns to select a <term class="other">sentence plan</term> whose <term class="other">rating</term> on average is only 5% worse than the <term class="other">top human-ranked sentence plan</term>.</S>  </Section></Paper>