{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_text(text, process_multiple_texts=False):\n",
    "    if process_multiple_texts:\n",
    "        text = ' '.join(text)\n",
    "    # Remove any empty space that are placed before special characters excpet for /, (, [, {\n",
    "    text = re.sub(r'\\s+([^\\w\\s(\\[\\{])', r'\\1', text)\n",
    "    \n",
    "    # Remove any empty space that are placed after the character /,(, [, {\n",
    "    text = re.sub(r'([/(\\[\\{])\\s+', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = text.lower().replace(' ', '')\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Filename: wind_en_01.txt is processing... #######\n",
      "###### Filename: wind_en_01.txt is finished! #######\n",
      "\n",
      "###### Filename: wind_en_02.txt is processing... #######\n",
      "###### Filename: wind_en_02.txt is finished! #######\n",
      "\n",
      "###### Filename: wind_en_04.txt is processing... #######\n",
      "###### Filename: wind_en_04.txt is finished! #######\n",
      "\n",
      "###### Filename: wind_en_26.txt is processing... #######\n",
      "###### Filename: wind_en_26.txt is finished! #######\n",
      "\n",
      "###### Filename: wind_en_32.txt is processing... #######\n",
      "###### Filename: wind_en_32.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_01.txt is processing... #######\n",
      "###### Filename: corp_en_01.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_02.txt is processing... #######\n",
      "###### Filename: corp_en_02.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_04.txt is processing... #######\n",
      "###### Filename: corp_en_04.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_05.txt is processing... #######\n",
      "###### Filename: corp_en_05.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_06.txt is processing... #######\n",
      "###### Filename: corp_en_06.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_07.txt is processing... #######\n",
      "###### Filename: corp_en_07.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_08.txt is processing... #######\n",
      "###### Filename: corp_en_08.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_09.txt is processing... #######\n",
      "###### Filename: corp_en_09.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_10.txt is processing... #######\n",
      "###### Filename: corp_en_10.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_11.txt is processing... #######\n",
      "###### Filename: corp_en_11.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_12.txt is processing... #######\n",
      "###### Filename: corp_en_12.txt is finished! #######\n",
      "\n",
      "###### Filename: corp_en_19.txt is processing... #######\n",
      "###### Filename: corp_en_19.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_001.txt is processing... #######\n",
      "###### Filename: htfl_en_001.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_002.txt is processing... #######\n",
      "###### Filename: htfl_en_002.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_003.txt is processing... #######\n",
      "###### Filename: htfl_en_003.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_004.txt is processing... #######\n",
      "###### Filename: htfl_en_004.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_005.txt is processing... #######\n",
      "###### Filename: htfl_en_005.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_006.txt is processing... #######\n",
      "###### Filename: htfl_en_006.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_007.txt is processing... #######\n",
      "###### Filename: htfl_en_007.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_008.txt is processing... #######\n",
      "###### Filename: htfl_en_008.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_009.txt is processing... #######\n",
      "###### Filename: htfl_en_009.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_010.txt is processing... #######\n",
      "###### Filename: htfl_en_010.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_011.txt is processing... #######\n",
      "###### Filename: htfl_en_011.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_012.txt is processing... #######\n",
      "###### Filename: htfl_en_012.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_013.txt is processing... #######\n",
      "###### Filename: htfl_en_013.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_014.txt is processing... #######\n",
      "###### Filename: htfl_en_014.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_015.txt is processing... #######\n",
      "###### Filename: htfl_en_015.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_016.txt is processing... #######\n",
      "###### Filename: htfl_en_016.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_017.txt is processing... #######\n",
      "###### Filename: htfl_en_017.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_018.txt is processing... #######\n",
      "###### Filename: htfl_en_018.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_019.txt is processing... #######\n",
      "###### Filename: htfl_en_019.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_020.txt is processing... #######\n",
      "###### Filename: htfl_en_020.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_021.txt is processing... #######\n",
      "###### Filename: htfl_en_021.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_022.txt is processing... #######\n",
      "###### Filename: htfl_en_022.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_023.txt is processing... #######\n",
      "###### Filename: htfl_en_023.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_024.txt is processing... #######\n",
      "###### Filename: htfl_en_024.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_025.txt is processing... #######\n",
      "###### Filename: htfl_en_025.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_026.txt is processing... #######\n",
      "###### Filename: htfl_en_026.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_027.txt is processing... #######\n",
      "###### Filename: htfl_en_027.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_028.txt is processing... #######\n",
      "###### Filename: htfl_en_028.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_029.txt is processing... #######\n",
      "###### Filename: htfl_en_029.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_030.txt is processing... #######\n",
      "###### Filename: htfl_en_030.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_031.txt is processing... #######\n",
      "###### Filename: htfl_en_031.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_032.txt is processing... #######\n",
      "###### Filename: htfl_en_032.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_033.txt is processing... #######\n",
      "###### Filename: htfl_en_033.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_034.txt is processing... #######\n",
      "###### Filename: htfl_en_034.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_035.txt is processing... #######\n",
      "###### Filename: htfl_en_035.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_036.txt is processing... #######\n",
      "###### Filename: htfl_en_036.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_037.txt is processing... #######\n",
      "###### Filename: htfl_en_037.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_038.txt is processing... #######\n",
      "###### Filename: htfl_en_038.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_039.txt is processing... #######\n",
      "###### Filename: htfl_en_039.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_040.txt is processing... #######\n",
      "###### Filename: htfl_en_040.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_041.txt is processing... #######\n",
      "###### Filename: htfl_en_041.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_042.txt is processing... #######\n",
      "###### Filename: htfl_en_042.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_043.txt is processing... #######\n",
      "###### Filename: htfl_en_043.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_044.txt is processing... #######\n",
      "###### Filename: htfl_en_044.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_045.txt is processing... #######\n",
      "###### Filename: htfl_en_045.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_046.txt is processing... #######\n",
      "###### Filename: htfl_en_046.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_047.txt is processing... #######\n",
      "###### Filename: htfl_en_047.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_048.txt is processing... #######\n",
      "###### Filename: htfl_en_048.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_049.txt is processing... #######\n",
      "###### Filename: htfl_en_049.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_050.txt is processing... #######\n",
      "###### Filename: htfl_en_050.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_051.txt is processing... #######\n",
      "###### Filename: htfl_en_051.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_052.txt is processing... #######\n",
      "###### Filename: htfl_en_052.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_053.txt is processing... #######\n",
      "###### Filename: htfl_en_053.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_054.txt is processing... #######\n",
      "###### Filename: htfl_en_054.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_055.txt is processing... #######\n",
      "###### Filename: htfl_en_055.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_056.txt is processing... #######\n",
      "###### Filename: htfl_en_056.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_057.txt is processing... #######\n",
      "###### Filename: htfl_en_057.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_058.txt is processing... #######\n",
      "###### Filename: htfl_en_058.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_059.txt is processing... #######\n",
      "###### Filename: htfl_en_059.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_060.txt is processing... #######\n",
      "###### Filename: htfl_en_060.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_061.txt is processing... #######\n",
      "###### Filename: htfl_en_061.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_062.txt is processing... #######\n",
      "###### Filename: htfl_en_062.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_063.txt is processing... #######\n",
      "###### Filename: htfl_en_063.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_064.txt is processing... #######\n",
      "###### Filename: htfl_en_064.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_065.txt is processing... #######\n",
      "###### Filename: htfl_en_065.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_066.txt is processing... #######\n",
      "###### Filename: htfl_en_066.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_067.txt is processing... #######\n",
      "###### Filename: htfl_en_067.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_068.txt is processing... #######\n",
      "###### Filename: htfl_en_068.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_069.txt is processing... #######\n",
      "###### Filename: htfl_en_069.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_070.txt is processing... #######\n",
      "###### Filename: htfl_en_070.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_071.txt is processing... #######\n",
      "###### Filename: htfl_en_071.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_072.txt is processing... #######\n",
      "###### Filename: htfl_en_072.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_073.txt is processing... #######\n",
      "###### Filename: htfl_en_073.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_074.txt is processing... #######\n",
      "###### Filename: htfl_en_074.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_075.txt is processing... #######\n",
      "###### Filename: htfl_en_075.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_076.txt is processing... #######\n",
      "###### Filename: htfl_en_076.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_077.txt is processing... #######\n",
      "###### Filename: htfl_en_077.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_078.txt is processing... #######\n",
      "###### Filename: htfl_en_078.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_079.txt is processing... #######\n",
      "###### Filename: htfl_en_079.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_080.txt is processing... #######\n",
      "###### Filename: htfl_en_080.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_081.txt is processing... #######\n",
      "###### Filename: htfl_en_081.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_082.txt is processing... #######\n",
      "###### Filename: htfl_en_082.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_083.txt is processing... #######\n",
      "###### Filename: htfl_en_083.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_084.txt is processing... #######\n",
      "###### Filename: htfl_en_084.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_085.txt is processing... #######\n",
      "###### Filename: htfl_en_085.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_086.txt is processing... #######\n",
      "###### Filename: htfl_en_086.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_087.txt is processing... #######\n",
      "###### Filename: htfl_en_087.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_088.txt is processing... #######\n",
      "###### Filename: htfl_en_088.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_089.txt is processing... #######\n",
      "###### Filename: htfl_en_089.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_090.txt is processing... #######\n",
      "###### Filename: htfl_en_090.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_091.txt is processing... #######\n",
      "###### Filename: htfl_en_091.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_092.txt is processing... #######\n",
      "###### Filename: htfl_en_092.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_093.txt is processing... #######\n",
      "###### Filename: htfl_en_093.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_094.txt is processing... #######\n",
      "###### Filename: htfl_en_094.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_095.txt is processing... #######\n",
      "###### Filename: htfl_en_095.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_096.txt is processing... #######\n",
      "###### Filename: htfl_en_096.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_097.txt is processing... #######\n",
      "###### Filename: htfl_en_097.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_098.txt is processing... #######\n",
      "###### Filename: htfl_en_098.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_099.txt is processing... #######\n",
      "###### Filename: htfl_en_099.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_100.txt is processing... #######\n",
      "###### Filename: htfl_en_100.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_101.txt is processing... #######\n",
      "###### Filename: htfl_en_101.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_102.txt is processing... #######\n",
      "###### Filename: htfl_en_102.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_103.txt is processing... #######\n",
      "###### Filename: htfl_en_103.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_104.txt is processing... #######\n",
      "###### Filename: htfl_en_104.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_105.txt is processing... #######\n",
      "###### Filename: htfl_en_105.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_106.txt is processing... #######\n",
      "###### Filename: htfl_en_106.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_107.txt is processing... #######\n",
      "###### Filename: htfl_en_107.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_108.txt is processing... #######\n",
      "###### Filename: htfl_en_108.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_109.txt is processing... #######\n",
      "###### Filename: htfl_en_109.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_110.txt is processing... #######\n",
      "###### Filename: htfl_en_110.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_111.txt is processing... #######\n",
      "###### Filename: htfl_en_111.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_112.txt is processing... #######\n",
      "###### Filename: htfl_en_112.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_113.txt is processing... #######\n",
      "###### Filename: htfl_en_113.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_114.txt is processing... #######\n",
      "###### Filename: htfl_en_114.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_115.txt is processing... #######\n",
      "###### Filename: htfl_en_115.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_116.txt is processing... #######\n",
      "###### Filename: htfl_en_116.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_117.txt is processing... #######\n",
      "###### Filename: htfl_en_117.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_118.txt is processing... #######\n",
      "###### Filename: htfl_en_118.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_119.txt is processing... #######\n",
      "###### Filename: htfl_en_119.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_120.txt is processing... #######\n",
      "###### Filename: htfl_en_120.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_121.txt is processing... #######\n",
      "###### Filename: htfl_en_121.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_122.txt is processing... #######\n",
      "###### Filename: htfl_en_122.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_123.txt is processing... #######\n",
      "###### Filename: htfl_en_123.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_124.txt is processing... #######\n",
      "###### Filename: htfl_en_124.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_125.txt is processing... #######\n",
      "###### Filename: htfl_en_125.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_126.txt is processing... #######\n",
      "###### Filename: htfl_en_126.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_127.txt is processing... #######\n",
      "###### Filename: htfl_en_127.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_128.txt is processing... #######\n",
      "###### Filename: htfl_en_128.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_129.txt is processing... #######\n",
      "###### Filename: htfl_en_129.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_130.txt is processing... #######\n",
      "###### Filename: htfl_en_130.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_131.txt is processing... #######\n",
      "###### Filename: htfl_en_131.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_132.txt is processing... #######\n",
      "###### Filename: htfl_en_132.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_133.txt is processing... #######\n",
      "###### Filename: htfl_en_133.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_134.txt is processing... #######\n",
      "###### Filename: htfl_en_134.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_135.txt is processing... #######\n",
      "###### Filename: htfl_en_135.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_136.txt is processing... #######\n",
      "###### Filename: htfl_en_136.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_137.txt is processing... #######\n",
      "###### Filename: htfl_en_137.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_138.txt is processing... #######\n",
      "###### Filename: htfl_en_138.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_139.txt is processing... #######\n",
      "###### Filename: htfl_en_139.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_140.txt is processing... #######\n",
      "###### Filename: htfl_en_140.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_141.txt is processing... #######\n",
      "###### Filename: htfl_en_141.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_142.txt is processing... #######\n",
      "###### Filename: htfl_en_142.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_143.txt is processing... #######\n",
      "###### Filename: htfl_en_143.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_144.txt is processing... #######\n",
      "###### Filename: htfl_en_144.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_145.txt is processing... #######\n",
      "###### Filename: htfl_en_145.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_146.txt is processing... #######\n",
      "###### Filename: htfl_en_146.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_147.txt is processing... #######\n",
      "###### Filename: htfl_en_147.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_148.txt is processing... #######\n",
      "###### Filename: htfl_en_148.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_149.txt is processing... #######\n",
      "###### Filename: htfl_en_149.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_150.txt is processing... #######\n",
      "###### Filename: htfl_en_150.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_151.txt is processing... #######\n",
      "###### Filename: htfl_en_151.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_152.txt is processing... #######\n",
      "###### Filename: htfl_en_152.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_153.txt is processing... #######\n",
      "###### Filename: htfl_en_153.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_154.txt is processing... #######\n",
      "###### Filename: htfl_en_154.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_155.txt is processing... #######\n",
      "###### Filename: htfl_en_155.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_156.txt is processing... #######\n",
      "###### Filename: htfl_en_156.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_157.txt is processing... #######\n",
      "###### Filename: htfl_en_157.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_158.txt is processing... #######\n",
      "###### Filename: htfl_en_158.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_159.txt is processing... #######\n",
      "###### Filename: htfl_en_159.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_160.txt is processing... #######\n",
      "###### Filename: htfl_en_160.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_161.txt is processing... #######\n",
      "###### Filename: htfl_en_161.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_162.txt is processing... #######\n",
      "###### Filename: htfl_en_162.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_163.txt is processing... #######\n",
      "###### Filename: htfl_en_163.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_164.txt is processing... #######\n",
      "###### Filename: htfl_en_164.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_165.txt is processing... #######\n",
      "###### Filename: htfl_en_165.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_166.txt is processing... #######\n",
      "###### Filename: htfl_en_166.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_167.txt is processing... #######\n",
      "###### Filename: htfl_en_167.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_168.txt is processing... #######\n",
      "###### Filename: htfl_en_168.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_169.txt is processing... #######\n",
      "###### Filename: htfl_en_169.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_170.txt is processing... #######\n",
      "###### Filename: htfl_en_170.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_171.txt is processing... #######\n",
      "###### Filename: htfl_en_171.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_172.txt is processing... #######\n",
      "###### Filename: htfl_en_172.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_173.txt is processing... #######\n",
      "###### Filename: htfl_en_173.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_174.txt is processing... #######\n",
      "###### Filename: htfl_en_174.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_175.txt is processing... #######\n",
      "###### Filename: htfl_en_175.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_176.txt is processing... #######\n",
      "###### Filename: htfl_en_176.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_177.txt is processing... #######\n",
      "###### Filename: htfl_en_177.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_178.txt is processing... #######\n",
      "###### Filename: htfl_en_178.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_179.txt is processing... #######\n",
      "###### Filename: htfl_en_179.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_180.txt is processing... #######\n",
      "###### Filename: htfl_en_180.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_181.txt is processing... #######\n",
      "###### Filename: htfl_en_181.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_182.txt is processing... #######\n",
      "###### Filename: htfl_en_182.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_183.txt is processing... #######\n",
      "###### Filename: htfl_en_183.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_184.txt is processing... #######\n",
      "###### Filename: htfl_en_184.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_185.txt is processing... #######\n",
      "###### Filename: htfl_en_185.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_186.txt is processing... #######\n",
      "###### Filename: htfl_en_186.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_187.txt is processing... #######\n",
      "###### Filename: htfl_en_187.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_188.txt is processing... #######\n",
      "###### Filename: htfl_en_188.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_189.txt is processing... #######\n",
      "###### Filename: htfl_en_189.txt is finished! #######\n",
      "\n",
      "###### Filename: htfl_en_190.txt is processing... #######\n",
      "###### Filename: htfl_en_190.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_001.txt is processing... #######\n",
      "###### Filename: equi_en_001.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_002.txt is processing... #######\n",
      "###### Filename: equi_en_002.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_003.txt is processing... #######\n",
      "###### Filename: equi_en_003.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_004.txt is processing... #######\n",
      "###### Filename: equi_en_004.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_005.txt is processing... #######\n",
      "###### Filename: equi_en_005.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_006.txt is processing... #######\n",
      "###### Filename: equi_en_006.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_007.txt is processing... #######\n",
      "###### Filename: equi_en_007.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_008.txt is processing... #######\n",
      "###### Filename: equi_en_008.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_009.txt is processing... #######\n",
      "###### Filename: equi_en_009.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_010.txt is processing... #######\n",
      "###### Filename: equi_en_010.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_011.txt is processing... #######\n",
      "###### Filename: equi_en_011.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_012.txt is processing... #######\n",
      "###### Filename: equi_en_012.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_013.txt is processing... #######\n",
      "###### Filename: equi_en_013.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_014.txt is processing... #######\n",
      "###### Filename: equi_en_014.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_015.txt is processing... #######\n",
      "###### Filename: equi_en_015.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_016.txt is processing... #######\n",
      "###### Filename: equi_en_016.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_017.txt is processing... #######\n",
      "###### Filename: equi_en_017.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_018.txt is processing... #######\n",
      "###### Filename: equi_en_018.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_019.txt is processing... #######\n",
      "###### Filename: equi_en_019.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_020.txt is processing... #######\n",
      "###### Filename: equi_en_020.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_021.txt is processing... #######\n",
      "###### Filename: equi_en_021.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_022.txt is processing... #######\n",
      "###### Filename: equi_en_022.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_023.txt is processing... #######\n",
      "###### Filename: equi_en_023.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_024.txt is processing... #######\n",
      "###### Filename: equi_en_024.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_025.txt is processing... #######\n",
      "###### Filename: equi_en_025.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_026.txt is processing... #######\n",
      "###### Filename: equi_en_026.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_027.txt is processing... #######\n",
      "###### Filename: equi_en_027.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_028.txt is processing... #######\n",
      "###### Filename: equi_en_028.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_029.txt is processing... #######\n",
      "###### Filename: equi_en_029.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_030.txt is processing... #######\n",
      "###### Filename: equi_en_030.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_031.txt is processing... #######\n",
      "###### Filename: equi_en_031.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_032.txt is processing... #######\n",
      "###### Filename: equi_en_032.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_033.txt is processing... #######\n",
      "###### Filename: equi_en_033.txt is finished! #######\n",
      "\n",
      "###### Filename: equi_en_034.txt is processing... #######\n",
      "###### Filename: equi_en_034.txt is finished! #######\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_dataset = pd.DataFrame(columns=['text', 'tokenized_text', 'label', 'unique_label'])\n",
    "master_path = 'en'    \n",
    "    \n",
    "for dataset_name in os.listdir(master_path):\n",
    "    rows = {}\n",
    "    all_domain_terms = []\n",
    "    all_tokenized_domain_terms =[]\n",
    "    all_domain_term_positions = []\n",
    "    all_candidate_words = []\n",
    "    all_texts = []\n",
    "    all_term_types = []\n",
    "    all_tokenized_texts = []\n",
    "    dataset_path = os.path.join(master_path, dataset_name, 'annotated')\n",
    "    \n",
    "    if dataset_name == 'cor':\n",
    "        continue\n",
    "    \n",
    "    for category in sorted(os.listdir(dataset_path)):\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        \n",
    "        if category == 'annotations':\n",
    "            for seq_annotation in sorted(os.listdir(category_path)):                                \n",
    "                if seq_annotation == 'sequential_annotations':\n",
    "                    iob_annotation_path = os.path.join(category_path, seq_annotation, 'iob_annotations', 'with_named_entities')\n",
    "                    for filename in sorted(os.listdir(iob_annotation_path), key=lambda x: int(os.path.splitext(x)[0].split('_')[2])):\n",
    "                        file_path = os.path.join(iob_annotation_path, filename)\n",
    "                        lines = pd.read_csv(file_path,  sep='\\t', na_values=[], skip_blank_lines=False, names=['word', 'boi'])\n",
    "                    \n",
    "                        split_indexes = lines[pd.isna(lines[['word', 'boi']]).all(axis=1)].index\n",
    "                        for prev_index, split_index in zip([-1]+list(split_indexes[:-1]), split_indexes):\n",
    "                            split_lines = lines.iloc[prev_index+1:split_index]\n",
    "                            tokenized_domain_terms = []\n",
    "                            domain_term_positions = []\n",
    "                            domain_term_position = []\n",
    "                            domain_terms = []\n",
    "                            domain_term = []\n",
    "                            candidate_words = []\n",
    "                            for i in range(len(split_lines)):\n",
    "                                candidate_word = split_lines.iloc[i]['word']                                    \n",
    "                                boi = split_lines.iloc[i]['boi']\n",
    "                                if candidate_word is np.nan and boi is not np.nan:\n",
    "                                    candidate_word = 'None'\n",
    "                                \n",
    "                                if boi == 'B':\n",
    "                                    if len(domain_term) == 0:\n",
    "                                        domain_term.append(candidate_word)\n",
    "                                        domain_term_position.append(i)\n",
    "                                    else:\n",
    "                                        tokenized_domain_terms.append(domain_term)\n",
    "                                        domain_term = normalize_text(domain_term, True)\n",
    "                                        domain_terms.append(domain_term)\n",
    "                                        domain_term = [candidate_word]\n",
    "                                        \n",
    "                                        domain_term_position.append(i)\n",
    "                                        domain_term_positions.append(domain_term_position)\n",
    "                                        domain_term_position = [i]\n",
    "                                elif boi == 'I':\n",
    "                                    domain_term.append(candidate_word)\n",
    "                                else:\n",
    "                                    if len(domain_term) > 0:\n",
    "                                        tokenized_domain_terms.append(domain_term)\n",
    "                                        domain_term = normalize_text(domain_term, True)\n",
    "                                        domain_terms.append(domain_term)\n",
    "                                        domain_term = []\n",
    "                                        \n",
    "                                        domain_term_position.append(i)\n",
    "                                        domain_term_positions.append(domain_term_position)\n",
    "                                        domain_term_position=[]\n",
    "                                                                                \n",
    "                                candidate_words.append(candidate_word.lower())\n",
    "                            \n",
    "                            if len(domain_term) > 0:\n",
    "                                tokenized_domain_terms.append(domain_term)\n",
    "                                domain_term = normalize_text(domain_term, True)\n",
    "                                domain_terms.append(domain_term)\n",
    "                                \n",
    "                                domain_term_position.append(i)\n",
    "                                domain_term_positions.append(domain_term_position)\n",
    "                                                                    \n",
    "                            all_domain_terms.append(domain_terms)\n",
    "                            all_tokenized_domain_terms.append(tokenized_domain_terms)\n",
    "                            all_domain_term_positions.append(domain_term_positions)\n",
    "                            # all_candidate_words.append(candidate_words)\n",
    "                            all_candidate_words.append(remove_special_characters(''.join(candidate_words)))\n",
    "                            \n",
    "                elif seq_annotation == 'unique_annotation_lists':\n",
    "                    unique_annotation_list_path = os.path.join(category_path, seq_annotation, f\"{dataset_name}_en_terms_nes.tsv\")\n",
    "                    lines = pd.read_csv(unique_annotation_list_path,  sep='\\t', names=['word', 'term_type'])\n",
    "                    for i, domain_terms in enumerate(all_domain_terms):\n",
    "                        term_types = []\n",
    "                        for domain_term in domain_terms:\n",
    "                            domain_term = domain_term.lower()\n",
    "                            term_type = ''\n",
    "                            count = 0\n",
    "                            while len(term_type) == 0:                                    \n",
    "                                if count==0:\n",
    "                                    term_type = lines[lines['word']==domain_term]['term_type']\n",
    "                                \n",
    "                                elif count==1:\n",
    "                                    character_removed_domain_term_wo_ws = re.sub(r'[^a-zA-Z0-9\\s]', '', domain_term)\n",
    "                                    term_type = lines[lines['word']==character_removed_domain_term_wo_ws]['term_type']\n",
    "                                    \n",
    "                                elif count==2:\n",
    "                                    character_removed_domain_term_w_ws = re.sub(r'[^a-zA-Z0-9\\s]', ' ', domain_term).split(' ')\n",
    "                                    for i in sorted(range(len(character_removed_domain_term_w_ws)), reverse=True):\n",
    "                                        for j in range(len(character_removed_domain_term_w_ws)):\n",
    "                                            sliced_dash_removed_domain_term_w_ws = ' '.join(character_removed_domain_term_w_ws[j:j+i])\n",
    "                                            term_type = lines[lines['word'].str.contains(sliced_dash_removed_domain_term_w_ws)]['term_type']\n",
    "                                            if len(term_type) > 0:\n",
    "                                                break\n",
    "                                        if len(term_type) > 0:\n",
    "                                            break\n",
    "                                \n",
    "                                elif count > 2:\n",
    "                                    term_type = 'Not Annotated'                                            \n",
    "                                    print(f'Path: {unique_annotation_list_path}, domain_term: {domain_term}, index: {i}')\n",
    "                                    break\n",
    "                                    \n",
    "                                count += 1                                    \n",
    "\n",
    "                            if not isinstance(term_type, str):\n",
    "                                term_type = term_type.astype(str).values[0]\n",
    "                            term_types.append(term_type)\n",
    "                        all_term_types.append(term_types)\n",
    "        \n",
    "\n",
    "        elif category == 'texts_tokenised':\n",
    "            i =0\n",
    "            for filename in sorted(os.listdir(category_path), key=lambda x: int(os.path.splitext(x)[0].split('_')[2])):\n",
    "                print(f'###### Filename: {filename} is processing... #######')\n",
    "                with open(os.path.join(category_path, filename), 'r') as f:\n",
    "                    tokenized_text = f.read().split('\\n')\n",
    "                    text = list(map(lambda x: normalize_text(x.strip(), False), tokenized_text))\n",
    "                    if text[-1] == '':\n",
    "                        text = text[:-1]\n",
    "                    all_texts.extend(text)\n",
    "                    # remove empty list from tokenized_text\n",
    "                    tokenized_text = list(filter(lambda x: x != '', tokenized_text))\n",
    "                    all_tokenized_texts.extend(list(map(lambda x: x.split(' '), tokenized_text)))\n",
    "                print(f'###### Filename: {filename} is finished! #######\\n')\n",
    "    \n",
    "    # Check if doamin terms are correctly extracted\n",
    "    for texts, domain_terms in zip(all_texts, all_domain_terms):\n",
    "        for domain_term in domain_terms:\n",
    "            if domain_term not in texts:\n",
    "                raise ValueError(f'{domain_term} is not in {texts}')\n",
    "            \n",
    "    rows = {'text': all_texts, 'tokenized_text': all_tokenized_texts, 'label': all_domain_terms, 'tokenized_label':all_tokenized_domain_terms, 'all_domain_term_positions':all_domain_term_positions, 'unique_label': all_term_types}\n",
    "    rows['dataset_name'] = [dataset_name]*len(all_texts)\n",
    "    if dataset_name == 'htfl':\n",
    "        rows['domain'] = ['Heart Failure']*len(all_texts)\n",
    "        test_dataset = pd.DataFrame(rows)\n",
    "    elif dataset_name == 'equi':\n",
    "        rows['domain'] = ['Equitation']*len(all_texts)\n",
    "        validation_dataset = pd.DataFrame(rows)\n",
    "    else:\n",
    "        dataset_name_to_domain = {'corp': 'Corruption', 'wind': 'Wind Energy'}\n",
    "        rows['domain'] = [dataset_name_to_domain[dataset_name]]*len(all_texts)\n",
    "        train_dataset = pd.concat([train_dataset, pd.DataFrame(rows)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE FILTERING:\n",
      "\n",
      "Train dataset length: 8640\n",
      "Validation dataset length: 3090\n",
      "Test dataset length: 2432\n"
     ]
    }
   ],
   "source": [
    "print('BEFORE FILTERING:\\n')\n",
    "print(f'Train dataset length: {len(train_dataset)}')\n",
    "print(f'Validation dataset length: {len(validation_dataset)}')\n",
    "print(f'Test dataset length: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset[train_dataset['text'].apply(lambda x: len(x) > 2)]\n",
    "validation_dataset = validation_dataset[validation_dataset['text'].apply(lambda x: len(x) > 2)]\n",
    "test_dataset = test_dataset[test_dataset['text'].apply(lambda x: len(x) > 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER FILTERING:\n",
      "\n",
      "Train dataset length: 4820\n",
      "Validation dataset length: 3006\n",
      "Test dataset length: 2432\n"
     ]
    }
   ],
   "source": [
    "print('AFTER FILTERING:\\n')\n",
    "print(f'Train dataset length: {len(train_dataset)}')\n",
    "print(f'Validation dataset length: {len(validation_dataset)}')\n",
    "print(f'Test dataset length: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_label</th>\n",
       "      <th>all_domain_term_positions</th>\n",
       "      <th>unique_label</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National trends in patient safety for four common conditions, 2005- 2011.</td>\n",
       "      <td>[National, trends, in, patient, safety, for, four, common, conditions, ,, 2005, -, 2011, ., ]</td>\n",
       "      <td>[patient, conditions]</td>\n",
       "      <td>[[patient], [conditions]]</td>\n",
       "      <td>[[3, 4], [8, 9]]</td>\n",
       "      <td>[Common_Term, Common_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The effects of more than a decade of national efforts dedicated to improve patient safety remain largely unclear.</td>\n",
       "      <td>[The, effects, of, more, than, a, decade, of, national, efforts, dedicated, to, improve, patient, safety, remain, largely, unclear, ., ]</td>\n",
       "      <td>[patient]</td>\n",
       "      <td>[[patient]]</td>\n",
       "      <td>[[13, 14]]</td>\n",
       "      <td>[Common_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This study used the Medicare Patient Safety Monitoring System (MPSMS) database to assess national trends in adverse event rates between 2005 through 2011 for patients hospitalized with acute myocardial infarction, congestive heart failure, pneumonia, or conditions requiring surgery.</td>\n",
       "      <td>[This, study, used, the, Medicare, Patient, Safety, Monitoring, System, (, MPSMS, ), database, to, assess, national, trends, in, adverse, event, rates, between, 2005, through, 2011, for, patients, hospitalized, with, acute, myocardial, infarction, ,, congestive, heart, failure, ,, pneumonia, ,, or, conditions, requiring, surgery, ., ]</td>\n",
       "      <td>[Medicare Patient Safety Monitoring System, MPSMS, adverse event, patients, hospitalized, acute myocardial infarction, congestive heart failure, pneumonia, conditions, surgery]</td>\n",
       "      <td>[[Medicare, Patient, Safety, Monitoring, System], [MPSMS], [adverse, event], [patients], [hospitalized], [acute, myocardial, infarction], [congestive, heart, failure], [pneumonia], [conditions], [surgery]]</td>\n",
       "      <td>[[4, 9], [10, 11], [18, 20], [26, 27], [27, 28], [29, 32], [33, 36], [37, 38], [40, 41], [42, 43]]</td>\n",
       "      <td>[Named_Entity, Named_Entity, Specific_Term, Common_Term, Common_Term, Specific_Term, Specific_Term, Common_Term, Common_Term, Common_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The analysis included a large study sample with more than 60,000 patients across 4372 hospitals.</td>\n",
       "      <td>[The, analysis, included, a, large, study, sample, with, more, than, 60,000, patients, across, 4372, hospitals, ., ]</td>\n",
       "      <td>[patients, hospitals]</td>\n",
       "      <td>[[patients], [hospitals]]</td>\n",
       "      <td>[[11, 12], [14, 15]]</td>\n",
       "      <td>[Common_Term, Common_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The results show a significant decline in adverse event rates for acute myocardial infarction and congestive heart failure, translating to an estimated 81,000 in-hospital adverse events averted in 20102011.</td>\n",
       "      <td>[The, results, show, a, significant, decline, in, adverse, event, rates, for, acute, myocardial, infarction, and, congestive, heart, failure, ,, translating, to, an, estimated, 81,000, in-hospital, adverse, events, averted, in, 20102011, ., ]</td>\n",
       "      <td>[significant, adverse event, acute myocardial infarction, congestive heart failure, in-hospital, adverse events]</td>\n",
       "      <td>[[significant], [adverse, event], [acute, myocardial, infarction], [congestive, heart, failure], [in-hospital], [adverse, events]]</td>\n",
       "      <td>[[4, 5], [7, 9], [11, 14], [15, 18], [24, 25], [25, 27]]</td>\n",
       "      <td>[OOD_Term, Specific_Term, Specific_Term, Specific_Term, Common_Term, Specific_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>However, there were no measurable overall improvements for patients admitted with pneumonia or surgical conditions.</td>\n",
       "      <td>[However, ,, there, were, no, measurable, overall, improvements, for, patients, admitted, with, pneumonia, or, surgical, conditions, ., ]</td>\n",
       "      <td>[patients, pneumonia, surgical, conditions]</td>\n",
       "      <td>[[patients], [pneumonia], [surgical], [conditions]]</td>\n",
       "      <td>[[9, 10], [12, 13], [14, 15], [15, 16]]</td>\n",
       "      <td>[Common_Term, Common_Term, Common_Term, Common_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Some events, such as pressure ulcers in surgical patients, actually increased despite considerable national attention to these problems.</td>\n",
       "      <td>[Some, events, ,, such, as, pressure, ulcers, in, surgical, patients, ,, actually, increased, despite, considerable, national, attention, to, these, problems, ., ]</td>\n",
       "      <td>[pressure ulcers, surgical, patients]</td>\n",
       "      <td>[[pressure, ulcers], [surgical], [patients]]</td>\n",
       "      <td>[[5, 7], [8, 9], [9, 10]]</td>\n",
       "      <td>[Specific_Term, Common_Term, Common_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This study suggests that national patient safety initiatives have led to real progress in some areas but have not created across-the-board improvements.</td>\n",
       "      <td>[This, study, suggests, that, national, patient, safety, initiatives, have, led, to, real, progress, in, some, areas, but, have, not, created, across-the-board, improvements, ., ]</td>\n",
       "      <td>[patient]</td>\n",
       "      <td>[[patient]]</td>\n",
       "      <td>[[5, 6]]</td>\n",
       "      <td>[Common_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cross-talk between the heart and adipose tissue in cachectic heart failure patients with respect to alterations in body composition: a prospective study.</td>\n",
       "      <td>[Cross-talk, between, the, heart, and, adipose, tissue, in, cachectic, heart, failure, patients, with, respect, to, alterations, in, body, composition, :, a, prospective, study, ., ]</td>\n",
       "      <td>[Cross-talk, heart, adipose tissue, cachectic heart failure, patients, prospective study]</td>\n",
       "      <td>[[Cross-talk], [heart], [adipose, tissue], [cachectic, heart, failure], [patients], [prospective, study]]</td>\n",
       "      <td>[[0, 1], [3, 4], [5, 7], [8, 11], [11, 12], [21, 23]]</td>\n",
       "      <td>[Specific_Term, Common_Term, Specific_Term, Specific_Term, Common_Term, Specific_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OBJECTIVES:</td>\n",
       "      <td>[OBJECTIVES, :, ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cardiac cachexia (CC) is associated with changes in body composition.</td>\n",
       "      <td>[Cardiac, cachexia, (, CC, ), is, associated, with, changes, in, body, composition, ., ]</td>\n",
       "      <td>[Cardiac cachexia, CC]</td>\n",
       "      <td>[[Cardiac, cachexia], [CC]]</td>\n",
       "      <td>[[0, 2], [3, 4]]</td>\n",
       "      <td>[Specific_Term, Specific_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lipolysis and increased energy expenditure caused by A- and B natriuretic peptides (NPs) have been suggested to play a role in CC.</td>\n",
       "      <td>[Lipolysis, and, increased, energy, expenditure, caused, by, A, -, and, B, natriuretic, peptides, (, NPs, ), have, been, suggested, to, play, a, role, in, CC, ., ]</td>\n",
       "      <td>[Lipolysis, A-, B natriuretic peptides, NPs, CC]</td>\n",
       "      <td>[[Lipolysis], [A, -], [B, natriuretic, peptides], [NPs], [CC]]</td>\n",
       "      <td>[[0, 1], [7, 9], [10, 13], [14, 15], [24, 25]]</td>\n",
       "      <td>[Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>We tested the hypothesis that neurohormones and adipokines are associated with body composition in CC and that a progressive loss of fat free mass (FFM) and fat mass (FM) takes place.</td>\n",
       "      <td>[We, tested, the, hypothesis, that, neurohormones, and, adipokines, are, associated, with, body, composition, in, CC, and, that, a, progressive, loss, of, fat, free, mass, (, FFM, ), and, fat, mass, (, FM, ), takes, place, ., ]</td>\n",
       "      <td>[neurohormones, adipokines, CC, fat free mass, FFM, fat mass, FM]</td>\n",
       "      <td>[[neurohormones], [adipokines], [CC], [fat, free, mass], [FFM], [fat, mass], [FM]]</td>\n",
       "      <td>[[5, 6], [7, 8], [14, 15], [21, 24], [25, 26], [28, 30], [31, 32]]</td>\n",
       "      <td>[Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>METHODS:</td>\n",
       "      <td>[METHODS, :, ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Body composition with regard to FFM, FM, and body fat distribution was assessed by dual energy X-ray absorptiometry (DXA) in 19 non-diabetic patients with chronic heart failure (CHF) and CC and 38 controls (non-cachectic CHF and individuals with prior myocardial infarction-both n= 19) who were followed for 12 months.</td>\n",
       "      <td>[Body, composition, with, regard, to, FFM, ,, FM, ,, and, body, fat, distribution, was, assessed, by, dual, energy, X-ray, absorptiometry, (, DXA, ), in, 19, non-diabetic, patients, with, chronic, heart, failure, (, CHF, ), and, CC, and, 38, controls, (, non-cachectic, CHF, and, individuals, with, prior, myocardial, infarction-both, n, =, 19, ), who, were, followed, for, 12, months, ., ]</td>\n",
       "      <td>[FFM, FM, dual energy X-ray absorptiometry, DXA, non-diabetic, patients, chronic heart failure, CHF, CC, non-cachectic CHF, myocardial infarction-both]</td>\n",
       "      <td>[[FFM], [FM], [dual, energy, X-ray, absorptiometry], [DXA], [non-diabetic], [patients], [chronic, heart, failure], [CHF], [CC], [non-cachectic, CHF], [myocardial, infarction-both]]</td>\n",
       "      <td>[[5, 6], [7, 8], [16, 20], [21, 22], [25, 26], [26, 27], [28, 31], [32, 33], [35, 36], [40, 42], [46, 48]]</td>\n",
       "      <td>[Specific_Term, Specific_Term, Specific_Term, Specific_Term, Common_Term, Common_Term, Common_Term, Common_Term, Specific_Term, Specific_Term, Specific_Term]</td>\n",
       "      <td>htfl</td>\n",
       "      <td>Heart Failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "0                                                                                                                                                                                                                                                        National trends in patient safety for four common conditions, 2005- 2011.   \n",
       "1                                                                                                                                                                                                                The effects of more than a decade of national efforts dedicated to improve patient safety remain largely unclear.   \n",
       "2                                      This study used the Medicare Patient Safety Monitoring System (MPSMS) database to assess national trends in adverse event rates between 2005 through 2011 for patients hospitalized with acute myocardial infarction, congestive heart failure, pneumonia, or conditions requiring surgery.   \n",
       "3                                                                                                                                                                                                                                 The analysis included a large study sample with more than 60,000 patients across 4372 hospitals.   \n",
       "4                                                                                                                  The results show a significant decline in adverse event rates for acute myocardial infarction and congestive heart failure, translating to an estimated 81,000 in-hospital adverse events averted in 20102011.   \n",
       "5                                                                                                                                                                                                              However, there were no measurable overall improvements for patients admitted with pneumonia or surgical conditions.   \n",
       "6                                                                                                                                                                                         Some events, such as pressure ulcers in surgical patients, actually increased despite considerable national attention to these problems.   \n",
       "7                                                                                                                                                                         This study suggests that national patient safety initiatives have led to real progress in some areas but have not created across-the-board improvements.   \n",
       "8                                                                                                                                                                        Cross-talk between the heart and adipose tissue in cachectic heart failure patients with respect to alterations in body composition: a prospective study.   \n",
       "9                                                                                                                                                                                                                                                                                                                      OBJECTIVES:   \n",
       "10                                                                                                                                                                                                                                                           Cardiac cachexia (CC) is associated with changes in body composition.   \n",
       "11                                                                                                                                                                                              Lipolysis and increased energy expenditure caused by A- and B natriuretic peptides (NPs) have been suggested to play a role in CC.   \n",
       "12                                                                                                                                         We tested the hypothesis that neurohormones and adipokines are associated with body composition in CC and that a progressive loss of fat free mass (FFM) and fat mass (FM) takes place.   \n",
       "13                                                                                                                                                                                                                                                                                                                        METHODS:   \n",
       "14  Body composition with regard to FFM, FM, and body fat distribution was assessed by dual energy X-ray absorptiometry (DXA) in 19 non-diabetic patients with chronic heart failure (CHF) and CC and 38 controls (non-cachectic CHF and individuals with prior myocardial infarction-both n= 19) who were followed for 12 months.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                            tokenized_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                            [National, trends, in, patient, safety, for, four, common, conditions, ,, 2005, -, 2011, ., ]   \n",
       "1                                                                                                                                                                                                                                                                 [The, effects, of, more, than, a, decade, of, national, efforts, dedicated, to, improve, patient, safety, remain, largely, unclear, ., ]   \n",
       "2                                                         [This, study, used, the, Medicare, Patient, Safety, Monitoring, System, (, MPSMS, ), database, to, assess, national, trends, in, adverse, event, rates, between, 2005, through, 2011, for, patients, hospitalized, with, acute, myocardial, infarction, ,, congestive, heart, failure, ,, pneumonia, ,, or, conditions, requiring, surgery, ., ]   \n",
       "3                                                                                                                                                                                                                                                                                     [The, analysis, included, a, large, study, sample, with, more, than, 60,000, patients, across, 4372, hospitals, ., ]   \n",
       "4                                                                                                                                                      [The, results, show, a, significant, decline, in, adverse, event, rates, for, acute, myocardial, infarction, and, congestive, heart, failure, ,, translating, to, an, estimated, 81,000, in-hospital, adverse, events, averted, in, 20102011, ., ]   \n",
       "5                                                                                                                                                                                                                                                                [However, ,, there, were, no, measurable, overall, improvements, for, patients, admitted, with, pneumonia, or, surgical, conditions, ., ]   \n",
       "6                                                                                                                                                                                                                                      [Some, events, ,, such, as, pressure, ulcers, in, surgical, patients, ,, actually, increased, despite, considerable, national, attention, to, these, problems, ., ]   \n",
       "7                                                                                                                                                                                                                      [This, study, suggests, that, national, patient, safety, initiatives, have, led, to, real, progress, in, some, areas, but, have, not, created, across-the-board, improvements, ., ]   \n",
       "8                                                                                                                                                                                                                   [Cross-talk, between, the, heart, and, adipose, tissue, in, cachectic, heart, failure, patients, with, respect, to, alterations, in, body, composition, :, a, prospective, study, ., ]   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                        [OBJECTIVES, :, ]   \n",
       "10                                                                                                                                                                                                                                                                                                                [Cardiac, cachexia, (, CC, ), is, associated, with, changes, in, body, composition, ., ]   \n",
       "11                                                                                                                                                                                                                                     [Lipolysis, and, increased, energy, expenditure, caused, by, A, -, and, B, natriuretic, peptides, (, NPs, ), have, been, suggested, to, play, a, role, in, CC, ., ]   \n",
       "12                                                                                                                                                                     [We, tested, the, hypothesis, that, neurohormones, and, adipokines, are, associated, with, body, composition, in, CC, and, that, a, progressive, loss, of, fat, free, mass, (, FFM, ), and, fat, mass, (, FM, ), takes, place, ., ]   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                          [METHODS, :, ]   \n",
       "14  [Body, composition, with, regard, to, FFM, ,, FM, ,, and, body, fat, distribution, was, assessed, by, dual, energy, X-ray, absorptiometry, (, DXA, ), in, 19, non-diabetic, patients, with, chronic, heart, failure, (, CHF, ), and, CC, and, 38, controls, (, non-cachectic, CHF, and, individuals, with, prior, myocardial, infarction-both, n, =, 19, ), who, were, followed, for, 12, months, ., ]   \n",
       "\n",
       "                                                                                                                                                                               label  \\\n",
       "0                                                                                                                                                              [patient, conditions]   \n",
       "1                                                                                                                                                                          [patient]   \n",
       "2   [Medicare Patient Safety Monitoring System, MPSMS, adverse event, patients, hospitalized, acute myocardial infarction, congestive heart failure, pneumonia, conditions, surgery]   \n",
       "3                                                                                                                                                              [patients, hospitals]   \n",
       "4                                                                   [significant, adverse event, acute myocardial infarction, congestive heart failure, in-hospital, adverse events]   \n",
       "5                                                                                                                                        [patients, pneumonia, surgical, conditions]   \n",
       "6                                                                                                                                              [pressure ulcers, surgical, patients]   \n",
       "7                                                                                                                                                                          [patient]   \n",
       "8                                                                                          [Cross-talk, heart, adipose tissue, cachectic heart failure, patients, prospective study]   \n",
       "9                                                                                                                                                                                 []   \n",
       "10                                                                                                                                                            [Cardiac cachexia, CC]   \n",
       "11                                                                                                                                  [Lipolysis, A-, B natriuretic peptides, NPs, CC]   \n",
       "12                                                                                                                 [neurohormones, adipokines, CC, fat free mass, FFM, fat mass, FM]   \n",
       "13                                                                                                                                                                                []   \n",
       "14                           [FFM, FM, dual energy X-ray absorptiometry, DXA, non-diabetic, patients, chronic heart failure, CHF, CC, non-cachectic CHF, myocardial infarction-both]   \n",
       "\n",
       "                                                                                                                                                                                                  tokenized_label  \\\n",
       "0                                                                                                                                                                                       [[patient], [conditions]]   \n",
       "1                                                                                                                                                                                                     [[patient]]   \n",
       "2   [[Medicare, Patient, Safety, Monitoring, System], [MPSMS], [adverse, event], [patients], [hospitalized], [acute, myocardial, infarction], [congestive, heart, failure], [pneumonia], [conditions], [surgery]]   \n",
       "3                                                                                                                                                                                       [[patients], [hospitals]]   \n",
       "4                                                                              [[significant], [adverse, event], [acute, myocardial, infarction], [congestive, heart, failure], [in-hospital], [adverse, events]]   \n",
       "5                                                                                                                                                             [[patients], [pneumonia], [surgical], [conditions]]   \n",
       "6                                                                                                                                                                    [[pressure, ulcers], [surgical], [patients]]   \n",
       "7                                                                                                                                                                                                     [[patient]]   \n",
       "8                                                                                                       [[Cross-talk], [heart], [adipose, tissue], [cachectic, heart, failure], [patients], [prospective, study]]   \n",
       "9                                                                                                                                                                                                              []   \n",
       "10                                                                                                                                                                                    [[Cardiac, cachexia], [CC]]   \n",
       "11                                                                                                                                                 [[Lipolysis], [A, -], [B, natriuretic, peptides], [NPs], [CC]]   \n",
       "12                                                                                                                             [[neurohormones], [adipokines], [CC], [fat, free, mass], [FFM], [fat, mass], [FM]]   \n",
       "13                                                                                                                                                                                                             []   \n",
       "14                           [[FFM], [FM], [dual, energy, X-ray, absorptiometry], [DXA], [non-diabetic], [patients], [chronic, heart, failure], [CHF], [CC], [non-cachectic, CHF], [myocardial, infarction-both]]   \n",
       "\n",
       "                                                                                     all_domain_term_positions  \\\n",
       "0                                                                                             [[3, 4], [8, 9]]   \n",
       "1                                                                                                   [[13, 14]]   \n",
       "2           [[4, 9], [10, 11], [18, 20], [26, 27], [27, 28], [29, 32], [33, 36], [37, 38], [40, 41], [42, 43]]   \n",
       "3                                                                                         [[11, 12], [14, 15]]   \n",
       "4                                                     [[4, 5], [7, 9], [11, 14], [15, 18], [24, 25], [25, 27]]   \n",
       "5                                                                      [[9, 10], [12, 13], [14, 15], [15, 16]]   \n",
       "6                                                                                    [[5, 7], [8, 9], [9, 10]]   \n",
       "7                                                                                                     [[5, 6]]   \n",
       "8                                                        [[0, 1], [3, 4], [5, 7], [8, 11], [11, 12], [21, 23]]   \n",
       "9                                                                                                           []   \n",
       "10                                                                                            [[0, 2], [3, 4]]   \n",
       "11                                                              [[0, 1], [7, 9], [10, 13], [14, 15], [24, 25]]   \n",
       "12                                          [[5, 6], [7, 8], [14, 15], [21, 24], [25, 26], [28, 30], [31, 32]]   \n",
       "13                                                                                                          []   \n",
       "14  [[5, 6], [7, 8], [16, 20], [21, 22], [25, 26], [26, 27], [28, 31], [32, 33], [35, 36], [40, 42], [46, 48]]   \n",
       "\n",
       "                                                                                                                                                     unique_label  \\\n",
       "0                                                                                                                                      [Common_Term, Common_Term]   \n",
       "1                                                                                                                                                   [Common_Term]   \n",
       "2                      [Named_Entity, Named_Entity, Specific_Term, Common_Term, Common_Term, Specific_Term, Specific_Term, Common_Term, Common_Term, Common_Term]   \n",
       "3                                                                                                                                      [Common_Term, Common_Term]   \n",
       "4                                                                             [OOD_Term, Specific_Term, Specific_Term, Specific_Term, Common_Term, Specific_Term]   \n",
       "5                                                                                                            [Common_Term, Common_Term, Common_Term, Common_Term]   \n",
       "6                                                                                                                       [Specific_Term, Common_Term, Common_Term]   \n",
       "7                                                                                                                                                   [Common_Term]   \n",
       "8                                                                          [Specific_Term, Common_Term, Specific_Term, Specific_Term, Common_Term, Specific_Term]   \n",
       "9                                                                                                                                                              []   \n",
       "10                                                                                                                                 [Specific_Term, Specific_Term]   \n",
       "11                                                                                    [Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term]   \n",
       "12                                                      [Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term, Specific_Term]   \n",
       "13                                                                                                                                                             []   \n",
       "14  [Specific_Term, Specific_Term, Specific_Term, Specific_Term, Common_Term, Common_Term, Common_Term, Common_Term, Specific_Term, Specific_Term, Specific_Term]   \n",
       "\n",
       "   dataset_name         domain  \n",
       "0          htfl  Heart Failure  \n",
       "1          htfl  Heart Failure  \n",
       "2          htfl  Heart Failure  \n",
       "3          htfl  Heart Failure  \n",
       "4          htfl  Heart Failure  \n",
       "5          htfl  Heart Failure  \n",
       "6          htfl  Heart Failure  \n",
       "7          htfl  Heart Failure  \n",
       "8          htfl  Heart Failure  \n",
       "9          htfl  Heart Failure  \n",
       "10         htfl  Heart Failure  \n",
       "11         htfl  Heart Failure  \n",
       "12         htfl  Heart Failure  \n",
       "13         htfl  Heart Failure  \n",
       "14         htfl  Heart Failure  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "test_dataset.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/raid6/yongchan/miniconda3/envs/ATE/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_dataset, preserve_index=False)\n",
    "validation_dataset = Dataset.from_pandas(validation_dataset, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|| 4820/4820 [00:00<00:00, 42161.11 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|| 3006/3006 [00:00<00:00, 49034.06 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|| 2432/2432 [00:00<00:00, 34766.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset_save_path = 'huggingface'\n",
    "os.makedirs(dataset_save_path, exist_ok=True)\n",
    "\n",
    "dataset = DatasetDict({'train': train_dataset, 'validation': validation_dataset, 'test': test_dataset})\n",
    "dataset.save_to_disk(dataset_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
