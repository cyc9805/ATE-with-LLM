<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="H01-1001">  <Title>Activity detection for information access to oral communication</Title>  <Section>    <SectionTitle>ABSTRACT</SectionTitle>    <S>         <term class="other">Oral communication</term> is ubiquitous and carries important information yet it is also time consuming to document.</S>    <S>Given the development of storage media and networks one could just record and store a conversation for documentation.</S>    <S>The question is, however, how an interesting information piece would be found in a <term class="tech">large database</term>.</S>    <S>Traditional <term class="tech">information retrieval techniques</term> use a <term class="model">histogram</term> of <term class="other">keywords</term> as the <term class="other">document representation</term> but <term class="other">oral communication</term> may offer additional <term class="model">indices</term> such as the time and place of the rejoinder and the attendance.</S>    <S>An alternative <term class="model">index</term> could be the activity such as discussing, planning, informing, story-telling, etc.</S>    <S>This paper addresses the problem of the automatic detection of those activities in meeting situation and everyday rejoinders.</S>    <S>Several extensions of this basic idea are being discussed and/or evaluated: Similar to activities one can define <term class="other">subsets</term> of larger <term class="tech">database</term> and detect those automatically which is shown on a large database of TV shows.</S>    <S>Emotions and other <term class="model">indices</term> such as the dominance distribution of speakers might be available on the surface and could be used directly.</S>    <S>Despite the small size of the <term class="tech">databases</term> used some results about the effectiveness of these <term class="model">indices</term> can be obtained.</S>  </Section></Paper>