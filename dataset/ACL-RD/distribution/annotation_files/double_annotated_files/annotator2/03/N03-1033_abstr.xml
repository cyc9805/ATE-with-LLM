<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="N03-1033">  <Title>Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network</Title>  <Section>    <SectionTitle>Abstract</SectionTitle>    <S>We present a new <term class="tech">part-of-speech tagger</term> that demonstrates the following ideas: (i) explicit use of both preceding and following <term class="other">tag contexts</term> via a <term class="model">dependency network representation</term>, (ii) broad use of <term class="other">lexical features</term>, including jointly conditioning on multiple consecutive words, (iii) effective use of <term class="other">priors</term> in <term class="model">conditional loglinear models</term>, and (iv) fine-grained modeling of <term class="other">unknown word features</term>.</S>    <S>Using these ideas together, the resulting <term class="tech">tagger</term> gives a 97.24% <term class="measure(ment)">accuracy</term> on the <term class="tool">Penn Treebank WSJ</term>, an <term class="other">error reduction</term> of 4.4% on the best previous single <term class="other">automatically learned tagging result</term>.</S>  </Section></Paper>