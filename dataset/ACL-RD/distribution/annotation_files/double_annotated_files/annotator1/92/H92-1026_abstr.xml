<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="H92-1026">  <Title>Towards History-based Grammars: Using Richer Models for Probabilistic Parsing</Title>  <Section>    <SectionTitle>ABSTRACT</SectionTitle>    <S>We describe a <term class="model">generative probabilistic model of natural language</term>, which we call <term class="tech">HBG</term>, that takes advantage of detailed <term class="other">linguistic information</term> to resolve <term class="other">ambiguity</term>.</S>    <S>         <term class="tech">HBG</term> incorporates <term class="other">lexical, syntactic, semantic, and structural information</term> from the <term class="other">parse tree</term> into the <term class="tech">disambiguation process</term> in a novel way.</S>    <S>We use a <term class="lr">corpus of bracketed sentences</term>, called a <term class="lr">Treebank</term>, in combination with <term class="tech">decision tree building</term> to tease out the relevant aspects of a <term class="other">parse tree</term> that will determine the correct <term class="other">parse</term> of a <term class="other">sentence</term>.</S>    <S>This stands in contrast to the usual approach of further <term class="other">grammar</term> tailoring via the usual <term class="other">linguistic introspection</term> in the hope of generating the correct <term class="other">parse</term>.</S>    <S>In <term class="measure(ment)">head-to-head tests</term> against one of the best existing robust <term class="tech">probabilistic parsing models</term>, which we call <term class="tech">P-CFG</term>, the <term class="tech">HBG model</term> significantly outperforms <term class="tech">P-CFG</term>, increasing the <term class="measure(ment)">parsing accuracy</term> rate from 60% to 75%, a 37% reduction in error.</S>  </Section>  <!--BQ 18.11.2015-->  </Paper>