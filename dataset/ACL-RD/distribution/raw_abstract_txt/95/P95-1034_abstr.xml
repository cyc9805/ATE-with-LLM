<?xml version="1.0" ?>
<Paper acl-id="P95-1034">
  <Title>Two-Level, Many-Paths Generation</Title>
  <Section>
    <SectionTitle>Abstract</SectionTitle>
    <S>Large-scale natural language generation requires the integration of vast amounts of knowledge: lexical, grammatical, and conceptual.</S>
    <S>A robust generator must be able to operate well even when pieces of knowledge are missing.</S>
    <S>It must also be robust against incomplete or inaccurate inputs.</S>
    <S>To attack these problems, we have built a hybrid generator, in which gaps in symbolic knowledge are filled by statistical methods.</S>
    <S>We describe algorithms and show experimental results.</S>
    <S>We also discuss how the hybrid generation model can be used to simplify current generators and enhance their portability, even when perfect knowledge is in principle obtainable.</S>
  </Section></Paper>