<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="P95-1027">  <Title>A Quantitative Evaluation of Linguistic Tests for the Automatic Prediction of Semantic Markedness</Title>  <Section>    <SectionTitle>Abstract</SectionTitle>    <S>We present a <term class="tech">corpus-based study</term> of methods that have been proposed in the linguistics literature for selecting the semantically unmarked term out of a pair of <term class="other">antonymous adjectives</term>.</S>    <S>Solutions to this problem are applicable to the more general task of selecting the positive term from the pair.</S>    <S>Using <term class="other">automatically collected data</term>, the <term class="measure(ment)">accuracy</term> and <term class="measure(ment)">applicability</term> of each method is quantified, and a <term class="tech">statistical analysis</term> of the <term class="measure(ment)">significance</term> of the results is performed.</S>    <S>We show that some simple methods are indeed good indicators for the answer to the problem while other proposed methods fail to perform better than would be attributable to <term class="other">chance</term>.</S>    <S>In addition, one of the simplest methods, <term class="measure(ment)">text frequency</term>, dominates all others.</S>    <S>We also apply two <term class="tech">generic statistical learning methods</term> for combining the indications of the individual methods, and compare their <term class="measure(ment)">performance</term> to the simple methods.</S>    <S>The most sophisticated <term class="tech">complex learning method</term> offers a small, but statistically significant, <term class="measure(ment)">improvement</term> over the original tests.</S>  </Section></Paper>