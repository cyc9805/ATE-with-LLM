<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="E06-1022">  <Title>Addressee Identification in Face-to-Face Meetings</Title>  <Section>    <SectionTitle>Abstract</SectionTitle>    <S>We present results on <term class="tech">addressee identification</term> in <term class="other">four-participants face-to-face meetings</term> using <term class="tech">Bayesian Network</term> and <term class="tech">Naive Bayes classifiers</term>.</S>    <S>First, we investigate how well the <term class="other">addressee</term> of a <term class="other">dialogue act</term> can be predicted based on <term class="other">gaze</term>, <term class="other">utterance</term> and <term class="other">conversational context features</term>.</S>    <S>Then, we explore whether information about <term class="other">meeting context</term> can aid <term class="tech">classifiers</term>' <term class="other">performances</term>.</S>    <S>Both <term class="tech">classifiers</term> perform the best when <term class="other">conversational context</term> and <term class="other">utterance features</term> are combined with <term class="other">speaker's gaze information</term>.</S>    <S>The <term class="tech">classifiers</term> show little <term class="other">gain</term> from information about <term class="other">meeting context</term>.</S>  </Section></Paper>