<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="H92-1026">  <Title>Towards History-based Grammars: Using Richer Models for Probabilistic Parsing</Title>  <Section>    <SectionTitle>ABSTRACT</SectionTitle>    <S>We describe a <term class="model">generative probabilistic model</term> of <term class="other">natural language</term>, which we call <term class="model">HBG</term>, that takes advantage of detailed <term class="other">linguistic information</term> to resolve <term class="other">ambiguity</term>.</S>    <S>         <term class="model">HBG</term> incorporates <term class="other">lexical, syntactic, semantic, and structural information</term> from the <term class="other">parse tree</term> into the <term class="other">disambiguation process</term> in a novel way.</S>    <S>We use a <term class="lr">corpus</term> of bracketed <term class="other">sentences</term>, called a <term class="lr">Treebank</term>, in combination with <term class="tech">decision tree building</term> to tease out the relevant aspects of a <term class="other">parse tree</term> that will determine the correct <term class="other">parse</term> of a <term class="other">sentence</term>.</S>    <S>This stands in contrast to the usual approach of further grammar tailoring via the usual <term class="other">linguistic introspection</term> in the hope of generating the correct <term class="other">parse</term>.</S>    <S>In head-to-head tests against one of the best existing <term class="model">robust probabilistic parsing models</term>, which we call <term class="model">P-CFG</term>, the <term class="model">HBG model</term> significantly outperforms <term class="model">P-CFG</term>, increasing the <term class="measure(ment)">parsing accuracy rate</term> from 60% to 75%, a 37% reduction in error.</S>  </Section></Paper>