<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="E06-1022">  <Title>Addressee Identification in Face-to-Face Meetings</Title>  <Section>    <SectionTitle>Abstract</SectionTitle>    <S>We present results on <term class="tech">addressee identification</term> in four-participants face-to-face meetings using <term class="tech">Bayesian Network and Naive Bayes classifiers</term>.</S>    <S>First, we investigate how well the <term class="other">addressee</term> of a <term class="other">dialogue act</term> can be predicted based on <term class="other">gaze, utterance and conversational context features</term>.</S>    <S>Then, we explore whether information about <term class="other">meeting context</term> can aid <term class="other">classifiers' performances</term>.</S>    <S>Both <term class="tech">classifiers</term> perform the best when <term class="other">conversational context</term> and <term class="other">utterance features</term> are combined with <term class="other">speaker's gaze information</term>.</S>    <S>The <term class="tech">classifiers</term> show little gain from information about <term class="other">meeting context</term>.</S>  </Section></Paper>