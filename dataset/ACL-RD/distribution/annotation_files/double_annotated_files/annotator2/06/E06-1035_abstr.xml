<?xml version="1.0" encoding="UTF-8" standalone="no"?><Paper acl-id="E06-1035">  <Title>Automatic Segmentation of Multiparty Dialogue</Title>  <Section>    <SectionTitle>Abstract</SectionTitle>    <S>In this paper, we investigate the problem of automatically predicting <term class="other">segment boundaries</term> in <term class="other">spoken multiparty dialogue</term>.</S>    <S>We extend prior work in two ways.</S>    <S>We first apply approaches that have been proposed for predicting <term class="other">top-level topic shifts</term> to the problem of identifying <term class="other">subtopic boundaries</term>.</S>    <S>We then explore the impact on performance of using <term class="other">ASR output</term> as opposed to <term class="other">human transcription</term>.</S>    <S>Examination of the effect of <term class="other">features</term> shows that predicting top-level and predicting <term class="other">subtopic boundaries</term> are two distinct tasks: (1) for predicting <term class="other">subtopic boundaries</term>, the <term class="tech">lexical cohesion-based approach</term> alone can achieve competitive results, (2) for predicting <term class="other">top-level boundaries</term>, the <term class="tech">machine learning approach</term> that combines <term class="other">lexical-cohesion and conversational features</term> performs best, and (3) <term class="other">conversational cues</term>, such as <term class="other">cue phrases</term> and <term class="other">overlapping speech</term>, are better indicators for the <term class="other">top-level prediction task</term>.</S>    <S>We also find that the <term class="other">transcription errors</term> inevitable in <term class="other">ASR output</term> have a negative impact on <term class="model">models</term> that combine <term class="other">lexical-cohesion and conversational features</term>, but do not change the general preference of approach for the two tasks.</S>  </Section></Paper>